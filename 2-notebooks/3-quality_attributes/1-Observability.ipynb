{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "54f0b7d7",
      "metadata": {},
      "source": [
        "# üçè Observability & Tracing Demo with `azure-ai-projects` and `azure-ai-inference` üçé\n",
        "\n",
        "Welcome to this **Health & Fitness**-themed notebook, where we'll explore how to set up **observability** and **tracing** for:\n",
        "\n",
        "1. **Basic LLM calls** using an `AIProjectClient`.\n",
        "2. **Multi-step** interactions using an **Agent** (such as a Health Resource Agent).\n",
        "3. **Tracing** your local usage in **console** (stdout) or via an **OTLP endpoint** (like **Prompty** or **Aspire**).\n",
        "4. Sending those **traces** to **Azure Monitor** (Application Insights) so you can view them in **Azure AI Foundry**.\n",
        "\n",
        "> **Disclaimer**: This is a fun demonstration of AI and observability! Any references to workouts, diets, or health routines in the code or prompts are purely for **educational** purposes. Always consult a professional for health advice.\n",
        "\n",
        "## Contents\n",
        "1. **Initialization**: Setting up environment, creating clients.\n",
        "2. **Basic LLM Call**: Quick demonstration of retrieving model completions.\n",
        "3. **Connections**: Listing project connections.\n",
        "4. **Observability & Tracing**\n",
        "   - **Console / Local** tracing\n",
        "   - **Prompty / Aspire**: piping traces to a local OTLP endpoint\n",
        "   - **Azure Monitor** tracing: hooking up to Application Insights\n",
        "   - **Verifying** your traces in Azure AI Foundry\n",
        "5. **Agent-based Example**:\n",
        "   - Creating a simple \"Health Resource Agent\" referencing sample docs.\n",
        "   - Multi-turn conversation with tracing.\n",
        "   - Cleanup.\n",
        "\n",
        "<img src=\"./seq-diagrams/1-observability.png\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e13f9f3",
      "metadata": {},
      "source": [
        "## 1. Initialization & Setup\n",
        "**Prerequisites**:\n",
        "- A `.env` file containing `PROJECT_CONNECTION_STRING` (and optionally `MODEL_DEPLOYMENT_NAME`).\n",
        "- Roles/permissions in Azure AI Foundry that let you do inference & agent creation.\n",
        "- A local environment with `azure-ai-projects`, `azure-ai-inference`, `opentelemetry` packages installed.\n",
        "\n",
        "**What we do**:\n",
        "- Load environment variables.\n",
        "- Initialize `AIProjectClient`.\n",
        "- Check that we can talk to a model (like `gpt-4o`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1ccdace",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully created AIProjectClient!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.inference.models import UserMessage, CompletionsFinishReason\n",
        "\n",
        "# Load environment variables\n",
        "notebook_path = Path().absolute()\n",
        "env_path = notebook_path.parent.parent / '.env'  # Adjust path as needed\n",
        "load_dotenv(env_path)\n",
        "\n",
        "connection_string = os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
        "if not connection_string:\n",
        "    raise ValueError(\"üö® PROJECT_CONNECTION_STRING not set in .env.\")\n",
        "\n",
        "# Initialize AIProjectClient\n",
        "try:\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=connection_string\n",
        "    )\n",
        "    print(\"‚úÖ Successfully created AIProjectClient!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating AIProjectClient: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e24461b",
      "metadata": {},
      "source": [
        "## 2. Basic LLM Call\n",
        "We'll do a **quick** chat completion request to confirm everything is working. We'll ask a simple question: \"How many feet are in a mile?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d7fcdaba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí°Response:\n",
            "There are **5,280 feet** in a mile.\n",
            "\n",
            "Finish reason: CompletionsFinishReason.STOPPED\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Create a ChatCompletions client\n",
        "    inference_client = project_client.inference.get_chat_completions_client()\n",
        "    # Default to \"gpt-4o\" if no env var is set\n",
        "    model_name = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\")\n",
        "\n",
        "    user_question = \"How many feet are in a mile?\"\n",
        "    response = inference_client.complete(\n",
        "        model=model_name,\n",
        "        messages=[UserMessage(content=user_question)]\n",
        "    )\n",
        "    print(\"\\nüí°Response:\")\n",
        "    print(response.choices[0].message.content)\n",
        "    print(\"\\nFinish reason:\", response.choices[0].finish_reason)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Could not complete the chat request:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b83517e",
      "metadata": {},
      "source": [
        "## 3. List & Inspect Connections\n",
        "Check out the **connections** your project has: these might be Azure OpenAI or other resource attachments. We'll just list them here for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b70793c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîé Found 6 total connections.\n",
            "1) Name: ai-vanhub14322613050517_aoai, Type: ConnectionType.AZURE_OPEN_AI, Endpoint: https://ai-vanhub14322613050517.openai.azure.com\n",
            "2) Name: ai-vanhub14322613050517, Type: ConnectionType.AZURE_AI_SERVICES, Endpoint: https://ai-vanhub14322613050517.cognitiveservices.azure.com\n",
            "3) Name: vancouveraisearch, Type: ConnectionType.AZURE_AI_SEARCH, Endpoint: https://vancouveraisearch.search.windows.net\n",
            "4) Name: vancouverbing, Type: ConnectionType.API_KEY, Endpoint: https://api.bing.microsoft.com\n",
            "5) Name: vancouver/workspaceartifactstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://stvanhub14322613050517.core.windows.net/9b21d268-39c4-4a54-a8a6-da3bc39c1cbe-azureml\n",
            "6) Name: vancouver/workspaceblobstore, Type: ConnectionType.AZURE_BLOB_STORAGE, Endpoint: https://stvanhub14322613050517.core.windows.net/9b21d268-39c4-4a54-a8a6-da3bc39c1cbe-azureml-blobstore\n",
            "\n",
            "üåÄ Found 1 Azure OpenAI connections:\n",
            "   -> ai-vanhub14322613050517_aoai\n",
            "\n",
            "‚≠ê Default Azure AI Services connection:\n",
            "{\n",
            " \"name\": \"ai-vanhub14322613050517\",\n",
            " \"id\": \"/subscriptions/3d467b8c-3894-4be7-a93e-a553d04b2e8e/resourceGroups/rg-vancouver14/providers/Microsoft.MachineLearningServices/workspaces/vancouver/connections/ai-vanhub14322613050517\",\n",
            " \"authentication_type\": \"ApiKey\",\n",
            " \"connection_type\": \"ConnectionType.AZURE_AI_SERVICES\",\n",
            " \"endpoint_url\": \"https://ai-vanhub14322613050517.cognitiveservices.azure.com\",\n",
            " \"key\": null\n",
            " \"token_credential\": null\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import ConnectionType\n",
        "\n",
        "all_conns = project_client.connections.list()\n",
        "print(f\"üîé Found {len(all_conns)} total connections.\")\n",
        "for idx, c in enumerate(all_conns):\n",
        "    print(f\"{idx+1}) Name: {c.name}, Type: {c.connection_type}, Endpoint: {c.endpoint_url}\")\n",
        "\n",
        "# Filter for Azure OpenAI connections\n",
        "aoai_conns = project_client.connections.list(connection_type=ConnectionType.AZURE_OPEN_AI)\n",
        "print(f\"\\nüåÄ Found {len(aoai_conns)} Azure OpenAI connections:\")\n",
        "for c in aoai_conns:\n",
        "    print(f\"   -> {c.name}\")\n",
        "\n",
        "# Get default connection of type AZURE_AI_SERVICES\n",
        "default_conn = project_client.connections.get_default(connection_type=ConnectionType.AZURE_AI_SERVICES,\n",
        "                                                     include_credentials=False)\n",
        "if default_conn:\n",
        "    print(\"\\n‚≠ê Default Azure AI Services connection:\")\n",
        "    print(default_conn)\n",
        "else:\n",
        "    print(\"No default connection found for Azure AI Services.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce0c8f7",
      "metadata": {},
      "source": [
        "# 4. Observability & Tracing\n",
        "\n",
        "We want to **collect telemetry** from our LLM calls, for example:\n",
        "- Timestamps of requests.\n",
        "- Latency.\n",
        "- Potential errors.\n",
        "- Optionally, the actual prompts & responses (if you enable content recording).\n",
        "\n",
        "We'll show how to set up:\n",
        "1. **Console** or local OTLP endpoint instrumentation.\n",
        "2. **Azure Monitor** instrumentation with Application Insights.\n",
        "3. **Viewing** your traces in Azure AI Foundry's portal.\n",
        "\n",
        "## 4.1 Local Console Debugging\n",
        "We'll install instrumentation packages and enable them. Then we'll do a quick chat call to see if logs appear in **stdout**.\n",
        "\n",
        "**Note**: If you want to see more advanced local dashboards, you can:\n",
        "- Use [Prompty](https://github.com/microsoft/prompty).\n",
        "- Use [Aspire Dashboard](https://learn.microsoft.com/dotnet/aspire/fundamentals/dashboard/standalone?tabs=bash) to visualize your OTLP traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "16d366bb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting opentelemetry-instrumentation-openai-v2\n",
            "  Downloading opentelemetry_instrumentation_openai_v2-2.1b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-api~=1.28 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-instrumentation~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions~=0.49b0 (from opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api~=1.28->opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting typing-extensions>=4.5.0 (from opentelemetry-api~=1.28->opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.28->opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting packaging>=18.0 (from opentelemetry-instrumentation~=0.49b0->opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation~=0.49b0->opentelemetry-instrumentation-openai-v2)\n",
            "  Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
            "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting grpcio<2.0.0,>=1.66.2 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk~=1.36.0 (from opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.36.0->opentelemetry-exporter-otlp-proto-grpc)\n",
            "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Downloading opentelemetry_instrumentation_openai_v2-2.1b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl (38 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl (4.5 MB)\n",
            "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
            "   -------------- ------------------------- 1.6/4.5 MB 8.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 4.2/4.5 MB 10.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.5/4.5 MB 10.2 MB/s  0:00:00\n",
            "Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: zipp, wrapt, typing-extensions, protobuf, packaging, grpcio, opentelemetry-proto, importlib-metadata, googleapis-common-protos, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-openai-v2, opentelemetry-exporter-otlp-proto-grpc\n",
            "\n",
            "   -- -------------------------------------  1/16 [wrapt]\n",
            "   ------- --------------------------------  3/16 [protobuf]\n",
            "   ------- --------------------------------  3/16 [protobuf]\n",
            "   ------- --------------------------------  3/16 [protobuf]\n",
            "   ------- --------------------------------  3/16 [protobuf]\n",
            "   ------- --------------------------------  3/16 [protobuf]\n",
            "   ---------- -----------------------------  4/16 [packaging]\n",
            "   ------------ ---------------------------  5/16 [grpcio]\n",
            "   ------------ ---------------------------  5/16 [grpcio]\n",
            "   ------------ ---------------------------  5/16 [grpcio]\n",
            "   ------------ ---------------------------  5/16 [grpcio]\n",
            "   --------------- ------------------------  6/16 [opentelemetry-proto]\n",
            "   --------------- ------------------------  6/16 [opentelemetry-proto]\n",
            "   --------------- ------------------------  6/16 [opentelemetry-proto]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   -------------------- -------------------  8/16 [googleapis-common-protos]\n",
            "   --------------- -----------  9/16 [opentelemetry-exporter-otlp-proto-common]\n",
            "   ------------------------- -------------- 10/16 [opentelemetry-api]\n",
            "   ------------------------- -------------- 10/16 [opentelemetry-api]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 11/16 [opentelemetry-semantic-conventions]\n",
            "   ------------------------------ --------- 12/16 [opentelemetry-sdk]\n",
            "   ------------------------------ --------- 12/16 [opentelemetry-sdk]\n",
            "   ------------------------------ --------- 12/16 [opentelemetry-sdk]\n",
            "   ------------------------------ ------- 13/16 [opentelemetry-instrumentation]\n",
            "   ------------------------------ ------- 13/16 [opentelemetry-instrumentation]\n",
            "   ------------------------ --- 14/16 [opentelemetry-instrumentation-openai-v2]\n",
            "   ----------------------------- 16/16 [opentelemetry-exporter-otlp-proto-grpc]\n",
            "\n",
            "Successfully installed googleapis-common-protos-1.70.0 grpcio-1.74.0 importlib-metadata-8.7.0 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-instrumentation-0.57b0 opentelemetry-instrumentation-openai-v2-2.1b0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 packaging-25.0 protobuf-6.31.1 typing-extensions-4.14.1 wrapt-1.17.2 zipp-3.23.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts opentelemetry-bootstrap.exe and opentelemetry-instrument.exe are installed in 'C:\\Users\\marcgarcia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "source": [
        "# You only need to install these once.\n",
        "!pip install opentelemetry-instrumentation-openai-v2 opentelemetry-exporter-otlp-proto-grpc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4767143a",
      "metadata": {},
      "source": [
        "### 4.1.1 Enable OpenTelemetry for Azure AI Inference\n",
        "We set environment variables to ensure:\n",
        "1. **Prompt content** is captured (optional!)\n",
        "2. The **Azure SDK** uses OpenTelemetry as its tracing implementation.\n",
        "3. We call `AIInferenceInstrumentor().instrument()` to patch and enable the instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ef06776",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Azure AI Inference instrumentation enabled.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from azure.ai.inference.tracing import AIInferenceInstrumentor\n",
        "\n",
        "# (Optional) capture prompt & completion contents in traces\n",
        "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"  # or 'false'\n",
        "\n",
        "# Let the Azure SDK know we want to use OpenTelemetry\n",
        "os.environ[\"AZURE_SDK_TRACING_IMPLEMENTATION\"] = \"opentelemetry\"\n",
        "\n",
        "# Instrument the Azure AI Inference client library\n",
        "AIInferenceInstrumentor().instrument()\n",
        "print(\"‚úÖ Azure AI Inference instrumentation enabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480fbc30",
      "metadata": {},
      "source": [
        "### 4.1.2 Point Traces to Console or Local OTLP\n",
        "The simplest is to pipe them to **stdout**. If you want to send them to **Prompty** or **Aspire**, specify the local OTLP endpoint URL (usually `\"http://localhost:4317\"` or similar)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d202f67d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Response: Sure! Here‚Äôs a simple **5-minute warmup routine** to get your body ready for exercise:\n",
            "\n",
            "1. **March or Jog in Place** ‚Äì 1 minute  \n",
            "   Get your heart rate up and start moving.\n",
            "\n",
            "2. **Arm Circles** ‚Äì 1 minute  \n",
            "   Stand tall and swing your arms in big circles, 30 seconds forward, 30 seconds backward.\n",
            "\n",
            "3. **Bodyweight Squats** ‚Äì 1 minute  \n",
            "   Feet shoulder-width apart, squat down and stand up. Go at a steady pace.\n",
            "\n",
            "4. **Torso Twists** ‚Äì 1 minute  \n",
            "   Stand with feet hip-width apart, twist your torso side to side, letting your arms swing loosely.\n",
            "\n",
            "5. **High Knees or Jumping Jacks** ‚Äì 1 minute  \n",
            "   Finish strong to get your blood flowing. Do high knees (lifting each knee up as high as possible), or do jumping jacks.\n",
            "\n",
            "**Tip:** Breathe naturally, move gently, and feel free to modify any movement to suit your body!\n"
          ]
        }
      ],
      "source": [
        "project_client.telemetry.enable(destination=sys.stdout)\n",
        "# Or, to send to a local OTLP collector (Prompty/Aspire), do:\n",
        "#   project_client.telemetry.enable(destination=\"http://localhost:4317\")\n",
        "\n",
        "try:\n",
        "    local_client = project_client.inference.get_chat_completions_client()\n",
        "    user_prompt = \"What's a simple 5-minute warmup routine?\"\n",
        "    local_resp = local_client.complete(\n",
        "        model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "        messages=[UserMessage(content=user_prompt)]\n",
        "    )\n",
        "    print(\"\\nü§ñ Response:\", local_resp.choices[0].message.content)\n",
        "except Exception as exc:\n",
        "    print(f\"‚ùå Error in local-tracing example: {exc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3c0fdd4",
      "metadata": {},
      "source": [
        "## 4.2 Azure Monitor Tracing (Application Insights)\n",
        "Now we'll set up tracing to **Application Insights**, which will forward your logs to the **Azure AI Foundry** **Tracing** page.\n",
        "\n",
        "**Steps**:\n",
        "1. In AI Foundry, go to your project‚Äôs **Tracing** tab, attach (or create) an **Application Insights** resource.\n",
        "2. In code, call `project_client.telemetry.get_connection_string()` to retrieve the instrumentation key.\n",
        "3. Use `azure.monitor.opentelemetry.configure_azure_monitor(...)` with that connection.\n",
        "4. Make an inference call -> logs appear in the Foundry portal (and in Azure Monitor itself).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "552014a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Found App Insights connection string, configuring...\n",
            "\n",
            "ü§ñ Response (logged to App Insights):\n",
            "Absolutely! Here are some easy at-home cardio exercises that require no equipment (just some space and comfortable shoes):\n",
            "\n",
            "**1. Jumping Jacks:**  \n",
            "Classic and effective. Do them in sets of 30-60 seconds.\n",
            "\n",
            "**2. High Knees:**  \n",
            "Jog in place, lifting your knees as high as possible.\n",
            "\n",
            "**3. Marching in Place:**  \n",
            "A lower-impact alternative to high knees. Pump your arms to raise your heart rate.\n",
            "\n",
            "**4. Mountain Climbers:**  \n",
            "Start in a plank position and alternate bringing knees toward your chest.\n",
            "\n",
            "**5. Dancing:**  \n",
            "Put on your favorite song and dance around! Great cardio and mood booster.\n",
            "\n",
            "**6. Step Touch:**  \n",
            "Step side to side, touching one foot next to the other. Swing your arms for extra movement.\n",
            "\n",
            "**7. Butt Kicks:**  \n",
            "Jog or march in place, aiming to kick your heels toward your glutes.\n",
            "\n",
            "**8. Fast Feet:**  \n",
            "Stand with knees slightly bent, and quickly tap your feet on the ground.\n",
            "\n",
            "**9. Shadow Boxing:**  \n",
            "Throw punches in the air while shifting your weight side to side.\n",
            "\n",
            "**10. Stair Climbing (if available):**  \n",
            "Walking or running up and down stairs is great for cardio (and legs!).\n",
            "\n",
            "**Tips:**  \n",
            "- Warm up for a few minutes before starting.\n",
            "- Combine a few exercises into a short circuit (e.g., 30 seconds each, repeat 3-5 times).\n",
            "- Listen to your body and modify for your fitness level.\n",
            "\n",
            "Let me know if you‚Äôd like a sample at-home cardio workout!\n"
          ]
        }
      ],
      "source": [
        "from azure.monitor.opentelemetry import configure_azure_monitor\n",
        "from azure.ai.inference.models import UserMessage\n",
        "\n",
        "app_insights_conn_str = project_client.telemetry.get_connection_string()\n",
        "if app_insights_conn_str:\n",
        "    print(\"üîß Found App Insights connection string, configuring...\")\n",
        "    configure_azure_monitor(connection_string=app_insights_conn_str)\n",
        "    # Optionally add more instrumentation (for openai or langchain):\n",
        "    project_client.telemetry.enable()\n",
        "    \n",
        "    # Let's do a test call that logs to AI Foundry's Tracing page\n",
        "    try:\n",
        "        with project_client.inference.get_chat_completions_client() as client:\n",
        "            prompt_msg = \"Any easy at-home cardio exercise recommendations?\"\n",
        "            response = client.complete(\n",
        "                model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "                messages=[UserMessage(content=prompt_msg)]\n",
        "            )\n",
        "            print(\"\\nü§ñ Response (logged to App Insights):\")\n",
        "            print(response.choices[0].message.content)\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Chat completions with Azure Monitor example failed:\", e)\n",
        "else:\n",
        "    print(\"No Application Insights connection string is configured in this project.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4991833",
      "metadata": {},
      "source": [
        "### 4.3 Viewing Traces in Azure AI Foundry\n",
        "After running the above code:\n",
        "1. Go to your AI Foundry project.\n",
        "2. Click **Tracing** on the sidebar.\n",
        "3. You should see the logs from your calls.\n",
        "4. Filter, expand, or explore them as needed.\n",
        "\n",
        "Also, if you want more advanced dashboards, you can open your **Application Insights** resource from the Foundry. In the App Insights portal, you get additional features like **end-to-end transaction** details, query logs, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31dbb932",
      "metadata": {},
      "source": [
        "# 5. Agent-based Example\n",
        "We'll now create a **Health Resource Agent** that references sample docs about recipes or guidelines, then demonstrate:\n",
        "1. Creating an Agent with instructions.\n",
        "2. Creating a conversation thread.\n",
        "3. Running multi-step queries with **observability** enabled.\n",
        "4. Optionally cleaning up resources at the end.\n",
        "\n",
        "> The agent approach is helpful when you want more sophisticated conversation flows or **tool usage** (like file search)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "303ad934",
      "metadata": {},
      "source": [
        "## 5.1 Create Sample Files & Vector Store\n",
        "We'll create dummy `.md` files about recipes/guidelines, then push them into a **vector store** so our agent can do semantic search.\n",
        "\n",
        "(*This portion is a quick summary‚Äîsee [the other file-search tutorial] if you need more details.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1e09113d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Created sample resource files: recipes.md, guidelines.md\n",
            "‚úÖ Uploaded: recipes.md -> File ID: assistant-C4gjJRMXVJmiSJEBnMmTjr\n",
            "‚úÖ Uploaded: guidelines.md -> File ID: assistant-KCGZ3FDTuZzALmSJJq7WUY\n",
            "üéâ Created vector store 'health_resources_example', ID: vs_YE8bAMpDuze4sisdvFJWE3vd\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import (\n",
        "    FileSearchTool,\n",
        "    FilePurpose,\n",
        "    MessageTextContent,\n",
        "    MessageRole\n",
        ")\n",
        "\n",
        "def create_sample_files():\n",
        "    \"\"\"Create some local .md files with sample text.\"\"\"\n",
        "    recipes_md = (\n",
        "        \"\"\"# Healthy Recipes Database\\n\\n\"\n",
        "        \"## Gluten-Free Recipes\\n\"\n",
        "        \"1. Quinoa Bowl\\n\"\n",
        "        \"   - Ingredients: quinoa, vegetables, olive oil\\n\"\n",
        "        \"   - Instructions: Cook quinoa, add vegetables\\n\\n\"\n",
        "        \"2. Rice Pasta\\n\"\n",
        "        \"   - Ingredients: rice pasta, mixed vegetables\\n\"\n",
        "        \"   - Instructions: Boil pasta, saut√© vegetables\\n\\n\"\n",
        "        \"## Diabetic-Friendly Recipes\\n\"\n",
        "        \"1. Low-Carb Stir Fry\\n\"\n",
        "        \"   - Ingredients: chicken, vegetables, tamari sauce\\n\"\n",
        "        \"   - Instructions: Cook chicken, add vegetables\\n\\n\"\n",
        "        \"## Heart-Healthy Recipes\\n\"\n",
        "        \"1. Baked Salmon\\n\"\n",
        "        \"   - Ingredients: salmon, lemon, herbs\\n\"\n",
        "        \"   - Instructions: Season salmon, bake\\n\\n\"\n",
        "        \"2. Mediterranean Bowl\\n\"\n",
        "        \"   - Ingredients: chickpeas, vegetables, tahini\\n\"\n",
        "        \"   - Instructions: Combine ingredients\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    guidelines_md = (\n",
        "        \"\"\"# Dietary Guidelines\\n\\n\"\n",
        "        \"## General Guidelines\\n\"\n",
        "        \"- Eat a variety of foods\\n\"\n",
        "        \"- Control portion sizes\\n\"\n",
        "        \"- Stay hydrated\\n\\n\"\n",
        "        \"## Special Diets\\n\"\n",
        "        \"1. Gluten-Free Diet\\n\"\n",
        "        \"   - Avoid wheat, barley, rye\\n\"\n",
        "        \"   - Focus on naturally gluten-free foods\\n\\n\"\n",
        "        \"2. Diabetic Diet\\n\"\n",
        "        \"   - Monitor carbohydrate intake\\n\"\n",
        "        \"   - Choose low glycemic foods\\n\\n\"\n",
        "        \"3. Heart-Healthy Diet\\n\"\n",
        "        \"   - Limit saturated fats\\n\"\n",
        "        \"   - Choose lean proteins\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(recipes_md)\n",
        "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(guidelines_md)\n",
        "\n",
        "    print(\"üìÑ Created sample resource files: recipes.md, guidelines.md\")\n",
        "    return [\"recipes.md\", \"guidelines.md\"]\n",
        "\n",
        "sample_files = create_sample_files()\n",
        "\n",
        "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
        "    try:\n",
        "        uploaded_ids = []\n",
        "        for fp in files:\n",
        "            upl = project_client.agents.upload_file_and_poll(\n",
        "                file_path=fp,\n",
        "                purpose=FilePurpose.AGENTS  # Add FilePurpose.AGENTS here\n",
        "            )\n",
        "            uploaded_ids.append(upl.id)\n",
        "            print(f\"‚úÖ Uploaded: {fp} -> File ID: {upl.id}\")\n",
        "\n",
        "        # Create vector store from these file IDs\n",
        "        vs = project_client.agents.create_vector_store_and_poll(\n",
        "            file_ids=uploaded_ids,\n",
        "            name=store_name\n",
        "        )\n",
        "        print(f\"üéâ Created vector store '{store_name}', ID: {vs.id}\")\n",
        "        return vs, uploaded_ids\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating vector store: {e}\")\n",
        "        return None, []\n",
        "\n",
        "vector_store, file_ids = None, []\n",
        "if sample_files:\n",
        "    vector_store, file_ids = create_vector_store(sample_files, store_name=\"health_resources_example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "145eb186",
      "metadata": {},
      "source": [
        "## 5.2 Create a Health Resource Agent\n",
        "We'll create a **FileSearchTool** referencing the vector store, then create an agent with instructions that it should:\n",
        "1. Provide disclaimers.\n",
        "2. Offer general nutrition or recipe tips.\n",
        "3. Cite sources if possible.\n",
        "4. Encourage professional consultation for deeper medical advice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7f604175",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéâ Created agent 'health-search-agent' with ID: asst_ifb9vnfjBZk7awt5vXyHCujV\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.projects.models import FileSearchTool, FilePurpose\n",
        "from azure.ai.projects.models import ConnectionType, MessageTextContent, MessageRole\n",
        "\n",
        "def create_health_agent(vs_id):\n",
        "    try:\n",
        "        # The tool references our vector store so the agent can search it\n",
        "        file_search_tool = FileSearchTool(vector_store_ids=[vs_id])\n",
        "        \n",
        "        instructions = \"\"\"\n",
        "            You are a health resource advisor with access to dietary and recipe files.\n",
        "            You:\n",
        "            1. Always present disclaimers (you're not a medical professional)\n",
        "            2. Provide references to files when possible\n",
        "            3. Focus on general nutrition or recipe tips.\n",
        "            4. Encourage professional consultation for more detailed advice.\n",
        "        \"\"\"\n",
        "\n",
        "        agent = project_client.agents.create_agent(\n",
        "            model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
        "            name=\"health-search-agent\",\n",
        "            instructions=instructions,\n",
        "            tools=file_search_tool.definitions,\n",
        "            tool_resources=file_search_tool.resources\n",
        "        )\n",
        "        print(f\"üéâ Created agent '{agent.name}' with ID: {agent.id}\")\n",
        "        return agent\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating health agent: {e}\")\n",
        "        return None\n",
        "\n",
        "health_agent = None\n",
        "if vector_store:\n",
        "    health_agent = create_health_agent(vector_store.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6995a6",
      "metadata": {},
      "source": [
        "## 5.3 Using the Agent\n",
        "Let's create a new conversation **thread** and ask the agent some questions. We'll rely on the **observability** settings we already configured so each step is traced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "86e5b4f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Created new thread, ID: thread_x5AHqTMGKPwTkrBK6kyCOc6X\n",
            "User asked: 'Could you suggest a gluten-free lunch recipe?'\n",
            "Run finished with status: RunStatus.COMPLETED\n",
            "User asked: 'Show me some heart-healthy meal ideas.'\n",
            "Run finished with status: RunStatus.COMPLETED\n",
            "User asked: 'What guidelines do you have for someone with diabetes?'\n",
            "Run finished with status: RunStatus.COMPLETED\n"
          ]
        }
      ],
      "source": [
        "def create_thread():\n",
        "    try:\n",
        "        thread = project_client.agents.create_thread()\n",
        "        print(f\"üìù Created new thread, ID: {thread.id}\")\n",
        "        return thread\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not create thread: {e}\")\n",
        "        return None\n",
        "\n",
        "def ask_question(thread_id, agent_id, user_question):\n",
        "    try:\n",
        "        # 1) Add user message\n",
        "        msg = project_client.agents.create_message(\n",
        "            thread_id=thread_id,\n",
        "            role=\"user\",\n",
        "            content=user_question\n",
        "        )\n",
        "        print(f\"User asked: '{user_question}'\")\n",
        "        # 2) Create & process a run\n",
        "        run = project_client.agents.create_and_process_run(\n",
        "            thread_id=thread_id,\n",
        "            agent_id=agent_id\n",
        "        )\n",
        "        print(f\"Run finished with status: {run.status}\")\n",
        "        if run.last_error:\n",
        "            print(\"Error details:\", run.last_error)\n",
        "        return run\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error asking question: {e}\")\n",
        "        return None\n",
        "\n",
        "if health_agent:\n",
        "    thread = create_thread()\n",
        "    if thread:\n",
        "        # Let's ask a few sample questions\n",
        "        queries = [\n",
        "            \"Could you suggest a gluten-free lunch recipe?\",\n",
        "            \"Show me some heart-healthy meal ideas.\",\n",
        "            \"What guidelines do you have for someone with diabetes?\"\n",
        "        ]\n",
        "        for q in queries:\n",
        "            ask_question(thread.id, health_agent.id, q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c61d8d",
      "metadata": {},
      "source": [
        "### 5.3.1 Viewing the conversation\n",
        "We can retrieve the conversation messages to see how the agent responded, check if it cited file passages, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1c57935",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üó£Ô∏è Conversation:\n",
            "[USER]: Could you suggest a gluten-free lunch recipe?\n",
            "\n",
            "[ASSISTANT]: Absolutely! Here‚Äôs a simple gluten-free lunch recipe idea:\n",
            "\n",
            "**Quinoa & Chickpea Salad**\n",
            "\n",
            "**Ingredients:**\n",
            "- 1 cup cooked quinoa (gluten-free)\n",
            "- 1 cup canned chickpeas, rinsed and drained\n",
            "- 1 cup cherry tomatoes, halved\n",
            "- 1/2 cucumber, diced\n",
            "- 1/4 cup chopped red onion\n",
            "- 1/4 cup feta cheese (optional)\n",
            "- 2 tbsp olive oil\n",
            "- Juice of 1 lemon\n",
            "- Salt and pepper to taste\n",
            "- Fresh parsley or mint to garnish\n",
            "\n",
            "**Instructions:**\n",
            "1. In a large bowl, combine quinoa, chickpeas, tomatoes, cucumber, red onion, and feta cheese.\n",
            "2. In a small bowl, whisk together olive oil, lemon juice, salt, and pepper.\n",
            "3. Pour the dressing over the salad and toss well.\n",
            "4. Garnish with chopped herbs.\n",
            "5. Serve chilled or at room temperature.\n",
            "\n",
            "This meal is naturally gluten-free, packed with protein, and very easy to prepare. For added flavor, try adding diced avocado or roasted sweet potatoes.\n",
            "\n",
            "**Disclaimer:** I am not a medical professional. If you have celiac disease or severe gluten sensitivity, double-check that all packaged ingredients are certified gluten-free and consult a registered dietitian for personalized advice. \n",
            "\n",
            "Would you like a warm gluten-free recipe or more lunch ideas?\n",
            "\n",
            "[USER]: Show me some heart-healthy meal ideas.\n",
            "\n",
            "[ASSISTANT]: Certainly! Here are some heart-healthy meal ideas for you. These recipes focus on whole grains, lean proteins, healthy fats, and plenty of fruits and vegetables, while being low in saturated fat, sodium, and added sugars.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Grilled Salmon with Quinoa & Steamed Broccoli\n",
            "- **Why it's heart-healthy**: Salmon is rich in omega-3 fatty acids, which are known to help lower cholesterol and reduce inflammation. Quinoa adds fiber, and broccoli brings vitamins and antioxidants.\n",
            "\n",
            "**How to prepare:**\n",
            "- Grill or bake salmon fillets with a squeeze of lemon and fresh herbs.\n",
            "- Serve with cooked quinoa and steamed broccoli on the side.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Lentil & Vegetable Soup\n",
            "- **Why it's heart-healthy**: Lentils are high in fiber and plant-based protein, which help support healthy cholesterol levels.\n",
            "\n",
            "**How to prepare:**\n",
            "- Saut√© onions, carrots, celery, and garlic in olive oil.\n",
            "- Add vegetable broth, rinsed lentils, diced tomatoes, and your favorite herbs.\n",
            "- Simmer until lentils are tender.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. Chickpea & Spinach Stir-Fry\n",
            "- **Why it's heart-healthy**: Chickpeas are a good source of plant protein and soluble fiber, and spinach is packed with heart-friendly nutrients.\n",
            "\n",
            "**How to prepare:**\n",
            "- Saut√© onions and garlic in a little olive oil.\n",
            "- Add chickpeas, spinach, diced tomatoes, and spices such as cumin and paprika.\n",
            "- Cook until spinach is wilted. Serve over brown rice or quinoa.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. Mediterranean Power Bowl\n",
            "- **Why it's heart-healthy**: This bowl combines whole grains, vegetables, and healthy fats from olive oil and avocado.\n",
            "\n",
            "**How to prepare:**\n",
            "- Layer cooked brown rice or quinoa with chopped cucumbers, tomatoes, bell peppers, olives, and avocado.\n",
            "- Top with a handful of mixed greens and a drizzle of olive oil and lemon.\n",
            "\n",
            "---\n",
            "\n",
            "### 5. Simple Berry & Nut Oatmeal (for breakfast or lunch)\n",
            "- **Why it's heart-healthy**: Oats contain soluble fiber, which can help lower blood cholesterol.\n",
            "\n",
            "**How to prepare:**\n",
            "- Cook rolled oats with water or unsweetened plant milk.\n",
            "- Top with fresh berries, a sprinkle of chia seeds, and a handful of walnuts.\n",
            "\n",
            "---\n",
            "\n",
            "**Disclaimer:** I am not a medical professional. For specific heart-health concerns or dietary needs, please consult with a registered dietitian or healthcare provider.\n",
            "\n",
            "Would you like detailed recipes for any of these ideas, or guidance on a specific dietary concern?\n",
            "\n",
            "[USER]: What guidelines do you have for someone with diabetes?\n",
            "\n",
            "[ASSISTANT]: Certainly! Here are general nutrition guidelines for someone with diabetes. Please note, these are for informational purposes only‚Äî**always consult a healthcare professional or registered dietitian for personalized advice.**\n",
            "\n",
            "---\n",
            "\n",
            "### General Nutrition Guidelines for Diabetes\n",
            "\n",
            "1. **Focus on Complex Carbohydrates**  \n",
            "   - Choose whole grains (brown rice, whole wheat, quinoa, oats) over refined grains.  \n",
            "   - Limit white bread, pastries, and other processed carbs.\n",
            "\n",
            "2. **Watch Carbohydrate Portions**  \n",
            "   - Monitor *how much* you eat at meals and snacks.  \n",
            "   - Use tools like carbohydrate counting or the plate method (half vegetables, one-quarter starch, one-quarter protein).\n",
            "\n",
            "3. **Eat Plenty of Non-Starchy Vegetables**  \n",
            "   - Include veggies like broccoli, spinach, peppers, carrots, and leafy greens.\n",
            "\n",
            "4. **Include Lean Proteins**  \n",
            "   - Opt for skinless poultry, fish, tofu, beans, and low-fat dairy.\n",
            "\n",
            "5. **Limit Added Sugars**  \n",
            "   - Avoid sugary drinks, desserts, and snacks; look for hidden sugars in processed foods.\n",
            "\n",
            "6. **Choose Healthy Fats**  \n",
            "   - Cook with olive oil or canola oil, eat nuts, seeds, avocados, and fatty fish.  \n",
            "   - Limit saturated fat and trans fats (like those in fried foods, processed meats, and packaged snacks).\n",
            "\n",
            "7. **Read Food Labels**  \n",
            "   - Check for total carbs, added sugars, and fiber content.\n",
            "\n",
            "8. **Control Sodium Intake**  \n",
            "   - Aim to reduce salt; excess sodium can increase blood pressure.\n",
            "\n",
            "9. **Plan Regular Meals and Snacks**  \n",
            "   - Eat regularly to help keep blood sugar stable. Avoid skipping meals.\n",
            "\n",
            "10. **Hydrate with Water**  \n",
            "    - Stick to water, unsweetened tea, or black coffee instead of sugar-sweetened beverages.\n",
            "\n",
            "---\n",
            "\n",
            "### Additional Tips\n",
            "\n",
            "- **Monitor blood sugars regularly** to see how foods affect you.\n",
            "- **Stay active** as exercise helps with blood sugar management.\n",
            "- **Limit alcohol** and always pair it with food if consumed.\n",
            "\n",
            "---\n",
            "\n",
            "**Disclaimer:** I'm not a medical professional. Dietary needs may vary for each individual. Please consult a registered dietitian or your healthcare provider for a personalized plan.\n",
            "\n",
            "If you have specific questions (like meal ideas or help with a grocery list), just let me know!\n",
            "\n",
            "\n",
            "üìé Checking for citations...\n"
          ]
        }
      ],
      "source": [
        "def display_thread(thread_id):\n",
        "    try:\n",
        "        messages = project_client.agents.list_messages(thread_id=thread_id)\n",
        "        print(\"\\nüó£Ô∏è Conversation:\")\n",
        "        for m in reversed(messages.data):\n",
        "            if m.content:\n",
        "                last_content = m.content[-1]\n",
        "                if hasattr(last_content, \"text\"):\n",
        "                    print(f\"[{m.role.upper()}]: {last_content.text.value}\\n\")\n",
        "\n",
        "        print(\"\\nüìé Checking for citations...\")\n",
        "        for c in messages.file_citation_annotations:\n",
        "            print(f\"- Citation snippet: '{c.text}' from file ID: {c.file_citation['file_id']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not display thread: {e}\")\n",
        "\n",
        "# If we created a thread above, let's read it\n",
        "if health_agent and thread:\n",
        "    display_thread(thread.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7420c39",
      "metadata": {},
      "source": [
        "# 6. Cleanup\n",
        "If desired, we can remove the vector store, files, and agent to keep things tidy. (In a real solution, you might keep them around.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f473cddc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cleanup_resources():\n",
        "    try:\n",
        "        if 'vector_store' in globals() and vector_store:\n",
        "            project_client.agents.delete_vector_store(vector_store.id)\n",
        "            print(\"üóëÔ∏è Deleted vector store.\")\n",
        "\n",
        "        if 'file_ids' in globals() and file_ids:\n",
        "            for fid in file_ids:\n",
        "                project_client.agents.delete_file(fid)\n",
        "            print(\"üóëÔ∏è Deleted uploaded files.\")\n",
        "\n",
        "        if 'health_agent' in globals() and health_agent:\n",
        "            project_client.agents.delete_agent(health_agent.id)\n",
        "            print(\"üóëÔ∏è Deleted health agent.\")\n",
        "\n",
        "        if 'sample_files' in globals() and sample_files:\n",
        "            for sf in sample_files:\n",
        "                if os.path.exists(sf):\n",
        "                    os.remove(sf)\n",
        "            print(\"üóëÔ∏è Deleted local sample files.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error cleaning up: {e}\")\n",
        "\n",
        "\n",
        "cleanup_resources()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4956d0ec",
      "metadata": {},
      "source": [
        "# üéâ Wrap-Up\n",
        "We've demonstrated:\n",
        "1. **Basic LLM calls** with `AIProjectClient`.\n",
        "2. **Listing connections** in your Azure AI Foundry project.\n",
        "3. **Observability & tracing** in both local (console, OTLP endpoint) and cloud (App Insights) contexts.\n",
        "4. A quick **Agent** scenario that uses a vector store for searching sample docs.\n",
        "\n",
        "## Next Steps\n",
        "- Check the **Tracing** tab in your Azure AI Foundry portal to see the logs.\n",
        "- Explore advanced queries in Application Insights.\n",
        "- Use [Prompty](https://github.com/microsoft/prompty) or [Aspire](https://learn.microsoft.com/dotnet/aspire/) for local telemetry dashboards.\n",
        "- Incorporate this approach into your **production** GenAI pipelines!\n",
        "\n",
        "> üèãÔ∏è **Health Reminder**: The LLM's suggestions are for demonstration only. For real health decisions, consult a professional.\n",
        "\n",
        "Happy Observing & Tracing! üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-foundry-workshop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "name": "Observability_and_Tracing_Comprehensive"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
