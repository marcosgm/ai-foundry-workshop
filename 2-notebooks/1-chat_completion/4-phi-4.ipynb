{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e99a5b8",
      "metadata": {},
      "source": [
        "# üçé Phi-4 Model with AIProjectClient üçè\n",
        "\n",
        "**Phi-4** is a next-generation open model that aims to provide near GPT-4o capabilities at a fraction of the cost, making it ideal for many enterprise or personal use cases. It's especially great for chain-of-thought reasoning and RAG (Retrieval Augmented Generation) scenarios.\n",
        "\n",
        "In this notebook, you'll see how to:\n",
        "1. **Initialize** an `AIProjectClient` for your Azure AI Foundry environment.\n",
        "2. **Chat** with the **Phi-4** model using `azure-ai-inference`.\n",
        "3. **Show** a Health & Fitness example, featuring disclaimers and wellness Q&A.\n",
        "4. **Enjoy** the value proposition of a cheaper alternative to GPT-4 with strong reasoning capabilities. üèãÔ∏è\n",
        "\n",
        "> **Disclaimer**: This is not medical advice. Please consult professionals.\n",
        "\n",
        "## Why Phi-4?\n",
        "Phi-4 is a 14B-parameter model trained on curated data for high reasoning performance.\n",
        "- **Cost-Effective**: Get GPT-4-level performance for many tasks without the GPT-4 price.\n",
        "- **Reasoning & RAG**: Perfect for chain-of-thought reasoning steps and retrieval augmented generation workflows.\n",
        "- **Generous Context Window**: 16K tokens, enabling more context or longer user conversations.\n",
        "\n",
        "<img src=\"./seq-diagrams/4-phi-4.png\" width=\"30%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93357dd",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "Below, we'll install and import the necessary libraries:\n",
        "- **azure-ai-projects**: For the `AIProjectClient`.\n",
        "- **azure-ai-inference**: For calling your model, specifically the chat completions.\n",
        "- **azure-identity**: For `DefaultAzureCredential`.\n",
        "\n",
        "Ensure you have a `.env` file with:\n",
        "```bash\n",
        "PROJECT_CONNECTION_STRING=<your-conn-string>\n",
        "SERVERLESS_MODEL_NAME=phi-4\n",
        "```\n",
        "\n",
        "> **Note**: It's recommended to complete the [`3-basic-rag.ipynb`](./3-basic-rag.ipynb) notebook before this one, as it covers important concepts that will be helpful here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b5634a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ AIProjectClient created successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment variables\n",
        "notebook_path = Path().absolute()\n",
        "parent_dir = notebook_path.parent.parent\n",
        "load_dotenv(parent_dir / '.env')\n",
        "\n",
        "conn_string = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
        "phi4_deployment = os.getenv(\"SERVERLESS_MODEL_NAME\", \"phi-4\")\n",
        "\n",
        "try:\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=conn_string,\n",
        "    )\n",
        "    print(\"‚úÖ AIProjectClient created successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error creating AIProjectClient:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "500d63ef",
      "metadata": {},
      "source": [
        "## 2. Chat with Phi-4 üçè\n",
        "We'll demonstrate a simple conversation using **Phi-4** in a health & fitness context. We'll define a system prompt that clarifies the role of the assistant. Then we'll ask some user queries.\n",
        "\n",
        "> Notice that Phi-4 is well-suited for chain-of-thought reasoning. We'll let it illustrate its reasoning steps for fun.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0bcc4772",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üó£Ô∏è User: I'm training for a 5K. Any tips on a weekly workout schedule?\n",
            "ü§ñ Phi-4: Training for a 5K is a great goal, and having a structured weekly workout schedule can help you prepare effectively. I'll provide a general plan that incorporates a mix of running, cross-training, and rest days. Remember, it's important to tailor any plan to your current fitness level and consult a healthcare professional before starting any new exercise regimen, especially if you have any medical concerns.\n",
            "\n",
            "### General 5K Training Schedule\n",
            "\n",
            "**Week 1-4: Building a Base**\n",
            "1. **Monday:** Rest or Active Recovery\n",
            "   - Gentle activities like walking or yoga.\n",
            "   \n",
            "2. **Tuesday:** Easy Run\n",
            "   - Start with 20-30 minutes at a comfortable pace.\n",
            "   \n",
            "3. **Wednesday:** Cross-Training\n",
            "   - Engage in activities like cycling, swimming, or strength training for 30-45 minutes.\n",
            "   \n",
            "4. **Thursday:** Interval Training\n",
            "   - Warm up for 5 minutes, then run at a faster pace for 1 minute followed by 2 minutes of walking or jogging. Repeat 6-8 times, then cool down for 5 minutes.\n",
            "   \n",
            "5. **Friday:** Rest or Active Recovery\n",
            "   - Similar to Monday.\n",
            "   \n",
            "6. **Saturday:** Long Run\n",
            "   - Start with 30-40 minutes at a steady pace. Gradually increase the time each week.\n",
            "   \n",
            "7. **Sunday:** Easy Run or Cross-Training\n",
            "   - 20-30 minutes of easy running or a light cross-training session.\n",
            "\n",
            "**Week 5-8: Increasing Intensity**\n",
            "1. **Monday:** Rest or Active Recovery\n",
            "   - Continue with gentle activities.\n",
            "   \n",
            "2. **Tuesday:** Tempo Run\n",
            "   - Warm up for 5 minutes, run at a challenging but sustainable pace for 20-25 minutes, then cool down for 5 minutes.\n",
            "   \n",
            "3. **Wednesday:** Cross-Training\n",
            "   - 30-45 minutes of moderate-intensity cross-training.\n",
            "   \n",
            "4. **Thursday:** Hill\n"
          ]
        }
      ],
      "source": [
        "def chat_with_phi4(user_question, chain_of_thought=False):\n",
        "    \"\"\"Send a chat request to the Phi-4 model with optional chain-of-thought.\"\"\"\n",
        "    # We'll define a system message with disclaimers:\n",
        "    system_prompt = (\n",
        "        \"You are a Phi-4 AI assistant, focusing on health and fitness.\\n\"\n",
        "        \"Remind users that you are not a medical professional, but can provide general info.\\n\"\n",
        "    )\n",
        "\n",
        "    # We can optionally instruct the model to show chain-of-thought. (Use carefully in production.)\n",
        "    if chain_of_thought:\n",
        "        system_prompt += \"Please show your step-by-step reasoning in your answer.\\n\"\n",
        "\n",
        "    # We create messages for system + user.\n",
        "    system_msg = SystemMessage(content=system_prompt)\n",
        "    user_msg = UserMessage(content=user_question)\n",
        "\n",
        "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
        "        response = chat_client.complete(\n",
        "            model=phi4_deployment,\n",
        "            messages=[system_msg, user_msg],\n",
        "            temperature=0.8,  # a bit creative\n",
        "            top_p=0.9,\n",
        "            max_tokens=400,\n",
        "        )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usage:\n",
        "question = \"I'm training for a 5K. Any tips on a weekly workout schedule?\"\n",
        "answer = chat_with_phi4(question, chain_of_thought=True)\n",
        "print(\"üó£Ô∏è User:\", question)\n",
        "print(\"ü§ñ Phi-4:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc68c40d",
      "metadata": {},
      "source": [
        "## 3. RAG-like Example (Stub)\n",
        "Phi-4 also excels in retrieval augmented generation scenarios, where you provide external context and let the model reason over it. Below is a **stub** example showing how you'd pass retrieved text as context.\n",
        "\n",
        "> In a real scenario, you'd embed & search for relevant passages, then feed them into the user/system message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "419ea578",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üó£Ô∏è User: How often should I run weekly to prepare for a 5K?\n",
            "ü§ñ Phi-4 (RAG): To prepare for a 5K, it's great that you're considering a structured running plan. Based on the context you've provided, here's a suggested approach:\n",
            "\n",
            "1. **Running Frequency**: Aim to run 3 times per week. This frequency allows for consistent training without overloading your body, which is crucial for building endurance and speed.\n",
            "\n",
            "2. **Cross-Training**: Incorporate cross-training activities on one or two of your non-running days. This can include cycling, swimming, or strength training, which will help improve overall fitness and reduce the risk of injury by balancing muscle groups.\n",
            "\n",
            "3. **Rest and Recovery**: Include at least one full rest day or an active recovery day each week. Active recovery could involve light activities like walking, yoga, or stretching, which aid in muscle repair and prevent burnout.\n",
            "\n",
            "4. **Progressive Training**: Gradually increase your running distance and intensity over time. Start with shorter runs and slowly build up to longer distances, ensuring you're comfortable and injury-free.\n",
            "\n",
            "5. **Long Run**: Once a week, include a longer run that is about 30-60% of your 5K distance. This helps build endurance.\n",
            "\n",
            "6. **Speed Work**: Incorporate one speed workout per week, such as intervals or tempo runs, to improve your pace.\n",
            "\n",
            "7. **Tapering**: In the week leading up to your 5K, reduce your mileage to allow your body to recover and be fresh for race day.\n",
            "\n",
            "Remember,\n"
          ]
        }
      ],
      "source": [
        "def chat_with_phi4_rag(user_question, retrieved_doc):\n",
        "    \"\"\"Simulate an RAG flow by appending retrieved context to the system prompt.\"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are Phi-4, helpful fitness AI.\\n\"\n",
        "        \"We have some context from the user's knowledge base: \\n\"\n",
        "        f\"{retrieved_doc}\\n\"\n",
        "        \"Please use this context to help your answer. If the context doesn't help, say so.\\n\"\n",
        "    )\n",
        "\n",
        "    system_msg = SystemMessage(content=system_prompt)\n",
        "    user_msg = UserMessage(content=user_question)\n",
        "\n",
        "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
        "        response = chat_client.complete(\n",
        "            model=phi4_deployment,\n",
        "            messages=[system_msg, user_msg],\n",
        "            temperature=0.3,\n",
        "            max_tokens=300,\n",
        "        )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Let's define a dummy doc snippet:\n",
        "doc_snippet = \"Recommended to run 3 times per week and mix with cross-training.\\n\" \\\n",
        "              \"Include rest days or active recovery days for muscle repair.\"\n",
        "\n",
        "user_q = \"How often should I run weekly to prepare for a 5K?\"\n",
        "rag_answer = chat_with_phi4_rag(user_q, doc_snippet)\n",
        "print(\"üó£Ô∏è User:\", user_q)\n",
        "print(\"ü§ñ Phi-4 (RAG):\", rag_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a33a375",
      "metadata": {},
      "source": [
        "## 4. Wrap-Up & Best Practices\n",
        "1. **Chain-of-Thought**: Great for debugging or certain QA tasks, but be mindful about revealing chain-of-thought to end users.\n",
        "2. **RAG**: Use `azure-ai-inference` with retrieval results to ground your answers.\n",
        "3. **OpenTelemetry**: Optionally integrate `opentelemetry-sdk` and `azure-core-tracing-opentelemetry` for full observability.\n",
        "4. **Evaluate**: Use `azure-ai-evaluation` to measure your model‚Äôs performance.\n",
        "5. **Cost & Performance**: Phi-4 aims to provide near GPT-4 performance at lower cost. Evaluate for your domain needs.\n",
        "\n",
        "## üéâ Congratulations!\n",
        "You've seen how to:\n",
        "- Use **Phi-4** with `AIProjectClient` and `azure-ai-inference`.\n",
        "- Create a **chat** flow with chain-of-thought.\n",
        "- Stub a **RAG** scenario.\n",
        "\n",
        "> Happy hacking! üèãÔ∏è\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-foundry-workshop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
